# 一、实体嵌入（openke）

## TrainDataLoader类

**初始化参数：**

- **in_path**：训练集文件夹的路径
- **tri_file**：训练所需三元组文件路径
- **ent_file**：实体文件路径
- **rel_file**：关系文件路径
- **batch_size**：单次传递给程序用以训练的数据（样本）个数，为空则一次传递完所有样本
- **nbatches**：迭代次数
- **threads**：线程数
- **sampling_mode**：样品模式，一般为normal
- **bern_flag**：是否启用负采样
- **filter_flag**：是否启用过滤器
- **neg_ent**：负实体数量
- **neg_rel**：负关系数量

----



## TestDataLoader类

**初始化参数：**

- **in_path**：测试文件夹路径
- **sampling_mode**：样品模式，一般为link
- **type_constrain**：关系约束，默认为存在关系约束

----



## TransE类

**初始化参数：**

- **ent_tot**：使用TrainDataLoader.get_ent_tot()获得
- **rel_tot**：使用TrainDataLoader.get_rel_tot()获得
- **dim**：生成的嵌入向量的维度，维度越大空间表达能力越强，训练成本越高
- **p_norm**：指定的范数，使用1即可
- **norm_flag**：是否进行L-P范数标准化，采用范式作为正则项，可以防止模型训练过拟合。
- **margin**：一个边际参数，表示正负样本之间的间距，代表正负样本之间的最大距离，有了margin不会让负样本的d变得无限大
- **epsilon**：与margin作用相同

**接口函数：**

- **get_parameters**：获得嵌入矩阵

---



## NegativeSampling类

**初始化参数：**

- **model**：所选用的模型，可选参数有transe、transd、transh、transr等
- **loss**：丢失率，可以使用MarginLoss(margin=5.0)
- **batch_size**：单次传递给程序用以训练的数据（样本）个数

----



## Trainer类

**初始化参数：**

- **model**：所选用的模型
- **data_loader**：数据加载器，即TrainDataLoader
- **train_times**：训练次数
- **alpha**：注意力机制中LeakyReLU函数的参数，不太清楚有什么作用
- **use_gpu**：是否使用gpu
- **opt_method**：优化器选择，可选参数为Adagrad、Adadelta、Adam和sgd
- **save_steps**：保存中间步骤
- **checkpoint_dir**：保存训练结果模型的目录

**接口函数：**

- **train_one_step**：训练一轮
- **run**：开始训练
- **set_model**：设置模型
- **set_save_steps**：保中间结果路径

----

![50e2ef0df1b34d2b8c21d30ddb4194d3](.\50e2ef0df1b34d2b8c21d30ddb4194d3.png)



# 二、关系推理（relationPrediction）

**参数:**

`--data`: 数据集路径

`--epochs_gat`: gat层训练的周期数，通过使用更多的Epochs和更大的训练数据集，可以进一步提升模型的性能

`--epochs_conv`: 卷积层训练的周期数

`--lr`: 初始学习率，合适的学习率能够使目标函数在合适的时间内收敛到局部最小值

`--weight_decay_gat`: gat层的L2正则化率

`--weight_decay_conv`: conv层的L2正则化率

`--get_2hop`: 是否获取由2个跳跃邻居组成的pickle对象

`--use_2hop`: 是否使用两跳关系进行训练

`--partial_2hop`: 是否只使用一个节点的一个两跳关系进行训练

`--output_folder`: 保存输出模型的路径

`--batch_size_gat`: gat的batch大小，较大的Batch可以提高训练的效率，但可能导致模型收敛不稳定。较小的Batch可以提供更稳定的梯度估计，但会增加训练的时间

`--valid_invalid_ratio_gat`: GAT训练的有效与无效三元组的比率

`--drop_gat`: gat层的退出概率

`--alpha`: LeakyRelu alphas for attention layer.

`--nheads_GAT`: 注意力头的数量

`--margin`: Margin used in hinge loss.

`--batch_size_conv`: conv的batch大小

`--alpha_conv`: LeakyRelu alphas for conv layer.

`--valid_invalid_ratio_conv`: conv训练的有效与无效三元组的比率

`--out_channels`: conv层的输出通道数量

`--drop_conv`: conv层的退出概率